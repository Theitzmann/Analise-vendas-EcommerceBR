{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d6a575-5611-4d0e-90b7-05d4acee5da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de dados ANTES da conversão:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_purchase_timestamp       99441 non-null  object\n",
      " 1   order_approved_at              99281 non-null  object\n",
      " 2   order_delivered_carrier_date   97658 non-null  object\n",
      " 3   order_delivered_customer_date  96476 non-null  object\n",
      " 4   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho base para os dados\n",
    "data_path = 'dados/'\n",
    "\n",
    "# Carregar o dataset de pedidos\n",
    "orders_df = pd.read_csv(os.path.join(data_path, 'olist_orders_dataset.csv'))\n",
    "\n",
    "# Vamos dar uma olhada rápida nos tipos de dados originais das colunas de data\n",
    "print(\"Tipos de dados ANTES da conversão:\")\n",
    "print(orders_df[['order_purchase_timestamp', \n",
    "                 'order_approved_at', \n",
    "                 'order_delivered_carrier_date', \n",
    "                 'order_delivered_customer_date', \n",
    "                 'order_estimated_delivery_date']].info())\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ad0d93-7475-420e-9ba4-bed01ed14bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de dados DEPOIS da conversão:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   customer_id                    99441 non-null  object        \n",
      " 2   order_status                   99441 non-null  object        \n",
      " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), object(3)\n",
      "memory usage: 6.1+ MB\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Primeiras linhas com datas convertidas:\n",
      "  order_purchase_timestamp   order_approved_at order_delivered_carrier_date  \\\n",
      "0      2017-10-02 10:56:33 2017-10-02 11:07:15          2017-10-04 19:55:00   \n",
      "1      2018-07-24 20:41:37 2018-07-26 03:24:27          2018-07-26 14:31:00   \n",
      "2      2018-08-08 08:38:49 2018-08-08 08:55:23          2018-08-08 13:50:00   \n",
      "3      2017-11-18 19:28:06 2017-11-18 19:45:59          2017-11-22 13:39:59   \n",
      "4      2018-02-13 21:18:39 2018-02-13 22:20:29          2018-02-14 19:46:34   \n",
      "\n",
      "  order_delivered_customer_date order_estimated_delivery_date  \n",
      "0           2017-10-10 21:25:13                    2017-10-18  \n",
      "1           2018-08-07 15:27:45                    2018-08-13  \n",
      "2           2018-08-17 18:06:29                    2018-09-04  \n",
      "3           2017-12-02 00:28:42                    2017-12-15  \n",
      "4           2018-02-16 18:17:02                    2018-02-26  \n"
     ]
    }
   ],
   "source": [
    "# Lista das colunas de data a serem convertidas\n",
    "date_columns = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date', \n",
    "                'order_estimated_delivery_date']\n",
    "\n",
    "# Loop para converter cada coluna para datetime\n",
    "for col in date_columns:\n",
    "    orders_df[col] = pd.to_datetime(orders_df[col], errors='coerce')\n",
    "\n",
    "# Verificar os tipos de dados APÓS a conversão\n",
    "print(\"Tipos de dados DEPOIS da conversão:\")\n",
    "orders_df.info()\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Você também pode inspecionar as primeiras linhas para ver o formato das datas convertidas\n",
    "print(\"Primeiras linhas com datas convertidas:\")\n",
    "print(orders_df[date_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcd4047-2ecb-4e96-b993-c5113e447b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- order_items_df ---\n",
      "Tipo de dado de 'shipping_limit_date' ANTES:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   shipping_limit_date  112650 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 880.2+ KB\n",
      "None\n",
      "\n",
      "Tipo de dado de 'shipping_limit_date' DEPOIS:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   order_id             112650 non-null  object        \n",
      " 1   order_item_id        112650 non-null  int64         \n",
      " 2   product_id           112650 non-null  object        \n",
      " 3   seller_id            112650 non-null  object        \n",
      " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
      " 5   price                112650 non-null  float64       \n",
      " 6   freight_value        112650 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 6.0+ MB\n",
      "\n",
      "Primeiras linhas com 'shipping_limit_date' convertida:\n",
      "  shipping_limit_date\n",
      "0 2017-09-19 09:45:35\n",
      "1 2017-05-03 11:05:13\n",
      "2 2018-01-18 14:48:30\n",
      "3 2018-08-15 10:10:18\n",
      "4 2017-02-13 13:57:51\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset de itens do pedido (se ainda não estiver carregado no notebook)\n",
    "order_items_df = pd.read_csv(os.path.join(data_path, 'olist_order_items_dataset.csv'))\n",
    "\n",
    "# Verificar o tipo de dado ANTES da conversão\n",
    "print(\"\\n--- order_items_df ---\")\n",
    "print(\"Tipo de dado de 'shipping_limit_date' ANTES:\")\n",
    "print(order_items_df[['shipping_limit_date']].info())\n",
    "\n",
    "# Converter a coluna para datetime\n",
    "order_items_df['shipping_limit_date'] = pd.to_datetime(order_items_df['shipping_limit_date'], errors='coerce')\n",
    "\n",
    "# Verificar o tipo de dado APÓS a conversão\n",
    "print(\"\\nTipo de dado de 'shipping_limit_date' DEPOIS:\")\n",
    "order_items_df.info() # Mostra o DataFrame todo, incluindo a coluna convertida\n",
    "print(\"\\nPrimeiras linhas com 'shipping_limit_date' convertida:\")\n",
    "print(order_items_df[['shipping_limit_date']].head())\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83acb514-3e8b-45ae-bd69-2d3191082d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- order_reviews_df ---\n",
      "Tipos de dados de colunas de data ANTES:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   review_creation_date     99224 non-null  object\n",
      " 1   review_answer_timestamp  99224 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      "Tipos de dados de colunas de data DEPOIS:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     11568 non-null  object        \n",
      " 4   review_comment_message   40977 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 5.3+ MB\n",
      "\n",
      "Primeiras linhas com datas de avaliação convertidas:\n",
      "  review_creation_date review_answer_timestamp\n",
      "0           2018-01-18     2018-01-18 21:46:59\n",
      "1           2018-03-10     2018-03-11 03:05:13\n",
      "2           2018-02-17     2018-02-18 14:36:24\n",
      "3           2017-04-21     2017-04-21 22:02:06\n",
      "4           2018-03-01     2018-03-02 10:26:53\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset de avaliações (se ainda não estiver carregado no notebook)\n",
    "order_reviews_df = pd.read_csv(os.path.join(data_path, 'olist_order_reviews_dataset.csv'))\n",
    "\n",
    "# Verificar os tipos de dados ANTES da conversão\n",
    "print(\"\\n--- order_reviews_df ---\")\n",
    "print(\"Tipos de dados de colunas de data ANTES:\")\n",
    "print(order_reviews_df[['review_creation_date', 'review_answer_timestamp']].info())\n",
    "\n",
    "# Colunas de data a serem convertidas\n",
    "date_columns_reviews = ['review_creation_date', 'review_answer_timestamp']\n",
    "\n",
    "# Loop para converter cada coluna para datetime\n",
    "for col in date_columns_reviews:\n",
    "    order_reviews_df[col] = pd.to_datetime(order_reviews_df[col], errors='coerce')\n",
    "\n",
    "# Verificar os tipos de dados APÓS da conversão\n",
    "print(\"\\nTipos de dados de colunas de data DEPOIS:\")\n",
    "order_reviews_df.info() # Mostra o DataFrame todo\n",
    "print(\"\\nPrimeiras linhas com datas de avaliação convertidas:\")\n",
    "print(order_reviews_df[date_columns_reviews].head())\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697ac282-b09d-4fc9-9292-0b4057bfa99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs em 'product_category_name' ANTES: 0\n",
      "NaNs em 'product_category_name' DEPOIS: 0\n",
      "\n",
      "Contagem da categoria 'desconhecida':\n",
      "610\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "NaNs em 'product_name_lenght' ANTES: 0\n",
      "NaNs em 'product_name_lenght' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'product_description_lenght' ANTES: 0\n",
      "NaNs em 'product_description_lenght' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'product_photos_qty' ANTES: 0\n",
      "NaNs em 'product_photos_qty' DEPOIS: 0\n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Informações do products_df após preencher NaNs:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32951 non-null  object \n",
      " 2   product_name_lenght         32951 non-null  float64\n",
      " 3   product_description_lenght  32951 non-null  float64\n",
      " 4   product_photos_qty          32951 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset de produtos (se ainda não estiver carregado)\n",
    "# products_df = pd.read_csv(os.path.join(data_path, 'olist_products_dataset.csv')) # Descomente se precisar recarregar\n",
    "\n",
    "print(\"NaNs em 'product_category_name' ANTES:\", products_df['product_category_name'].isnull().sum())\n",
    "\n",
    "# Preencher os NaNs com \"desconhecida\" (forma recomendada)\n",
    "products_df['product_category_name'] = products_df['product_category_name'].fillna('desconhecida')\n",
    "\n",
    "print(\"NaNs em 'product_category_name' DEPOIS:\", products_df['product_category_name'].isnull().sum())\n",
    "\n",
    "print(\"\\nContagem da categoria 'desconhecida':\")\n",
    "print(products_df['product_category_name'].value_counts().get('desconhecida', 0))\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "cols_to_fill_zero = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty']\n",
    "\n",
    "for col in cols_to_fill_zero:\n",
    "    print(f\"NaNs em '{col}' ANTES:\", products_df[col].isnull().sum())\n",
    "    # Preencher os NaNs com 0 (forma recomendada)\n",
    "    products_df[col] = products_df[col].fillna(0)\n",
    "    print(f\"NaNs em '{col}' DEPOIS:\", products_df[col].isnull().sum())\n",
    "    print(\"---\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "print(\"Informações do products_df após preencher NaNs:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7ccd3d-3ec9-4cc0-9555-b8170c7e88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs em 'product_weight_g' ANTES: 2, Mediana: 700.0\n",
      "NaNs em 'product_weight_g' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'product_length_cm' ANTES: 2, Mediana: 25.0\n",
      "NaNs em 'product_length_cm' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'product_height_cm' ANTES: 2, Mediana: 13.0\n",
      "NaNs em 'product_height_cm' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'product_width_cm' ANTES: 2, Mediana: 20.0\n",
      "NaNs em 'product_width_cm' DEPOIS: 0\n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Informações do products_df após preencher NaNs de dimensão/peso:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32951 non-null  object \n",
      " 2   product_name_lenght         32951 non-null  float64\n",
      " 3   product_description_lenght  32951 non-null  float64\n",
      " 4   product_photos_qty          32951 non-null  float64\n",
      " 5   product_weight_g            32951 non-null  float64\n",
      " 6   product_length_cm           32951 non-null  float64\n",
      " 7   product_height_cm           32951 non-null  float64\n",
      " 8   product_width_cm            32951 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Colunas com 2 NaNs restantes\n",
    "cols_dimensions_weight = ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
    "\n",
    "for col in cols_dimensions_weight:\n",
    "    # Calcular a mediana da coluna (ignorando os NaNs existentes para o cálculo da mediana)\n",
    "    median_val = products_df[col].median()\n",
    "    print(f\"NaNs em '{col}' ANTES: {products_df[col].isnull().sum()}, Mediana: {median_val}\")\n",
    "    # Preencher os NaNs com a mediana\n",
    "    products_df[col] = products_df[col].fillna(median_val)\n",
    "    print(f\"NaNs em '{col}' DEPOIS: {products_df[col].isnull().sum()}\")\n",
    "    print(\"---\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "print(\"Informações do products_df após preencher NaNs de dimensão/peso:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899a97af-8ada-415f-a9b3-28bf8fc5ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de produtos com product_weight_g == 0.0: 4\n",
      "\n",
      "Alguns exemplos de produtos com peso zero:\n",
      "                             product_id product_category_name  \\\n",
      "9769   81781c0fed9fe1ad6e8c81fca1e1cb08       cama_mesa_banho   \n",
      "13683  8038040ee2a71048d4bdbbdc985b69ab       cama_mesa_banho   \n",
      "14997  36ba42dd187055e1fbe943b2d11430ca       cama_mesa_banho   \n",
      "32079  e673e90efa65a5409ff4196c038bb5af       cama_mesa_banho   \n",
      "\n",
      "       product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "9769                  51.0                       529.0                 1.0   \n",
      "13683                 48.0                       528.0                 1.0   \n",
      "14997                 53.0                       528.0                 1.0   \n",
      "32079                 53.0                       528.0                 1.0   \n",
      "\n",
      "       product_weight_g  product_length_cm  product_height_cm  \\\n",
      "9769                0.0               30.0               25.0   \n",
      "13683               0.0               30.0               25.0   \n",
      "14997               0.0               30.0               25.0   \n",
      "32079               0.0               30.0               25.0   \n",
      "\n",
      "       product_width_cm  \n",
      "9769               30.0  \n",
      "13683              30.0  \n",
      "14997              30.0  \n",
      "32079              30.0  \n",
      "\n",
      "Categorias dos produtos com peso zero:\n",
      "product_category_name\n",
      "cama_mesa_banho    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar produtos com peso igual a zero\n",
    "produtos_peso_zero_df = products_df[products_df['product_weight_g'] == 0.0]\n",
    "num_produtos_peso_zero = len(produtos_peso_zero_df)\n",
    "\n",
    "print(f\"Número de produtos com product_weight_g == 0.0: {num_produtos_peso_zero}\")\n",
    "\n",
    "# Se houver produtos com peso zero, vamos dar uma olhada em alguns deles e suas categorias\n",
    "if num_produtos_peso_zero > 0:\n",
    "    print(\"\\nAlguns exemplos de produtos com peso zero:\")\n",
    "    # Exibir colunas relevantes para tentar entender o contexto\n",
    "    print(produtos_peso_zero_df[['product_id', 'product_category_name', 'product_name_lenght', \n",
    "                                 'product_description_lenght', 'product_photos_qty', 'product_weight_g', \n",
    "                                 'product_length_cm', 'product_height_cm', 'product_width_cm']].head())\n",
    "    \n",
    "    print(\"\\nCategorias dos produtos com peso zero:\")\n",
    "    print(produtos_peso_zero_df['product_category_name'].value_counts())\n",
    "else:\n",
    "    print(\"Nenhum produto com peso zero encontrado!\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3aa053d-92d5-41b8-b74d-2c29212bd3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana do peso para a categoria 'cama_mesa_banho' (excluindo zeros): 1250.0g\n",
      "\n",
      "O peso dos 4 produtos da categoria 'cama_mesa_banho' que eram zero foi atualizado para: 1250.0g\n",
      "Número de produtos com product_weight_g == 0.0 DEPOIS da imputação: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular a mediana do peso para a categoria 'cama_mesa_banho'\n",
    "#    (excluindo os produtos que já têm peso 0 para não distorcer a mediana)\n",
    "median_weight_cama_mesa_banho = products_df[\n",
    "    (products_df['product_category_name'] == 'cama_mesa_banho') & \n",
    "    (products_df['product_weight_g'] > 0)  # Considera apenas pesos maiores que zero para o cálculo\n",
    "]['product_weight_g'].median()\n",
    "\n",
    "print(f\"Mediana do peso para a categoria 'cama_mesa_banho' (excluindo zeros): {median_weight_cama_mesa_banho}g\")\n",
    "\n",
    "# 2. Imputar a mediana nos produtos com peso zero da categoria 'cama_mesa_banho'\n",
    "#    Usamos .loc para selecionar as linhas e a coluna específica a ser modificada.\n",
    "if pd.notna(median_weight_cama_mesa_banho): # Verifica se a mediana foi calculada (não é NaN)\n",
    "    products_df.loc[\n",
    "        (products_df['product_weight_g'] == 0.0) & \n",
    "        (products_df['product_category_name'] == 'cama_mesa_banho'),\n",
    "        'product_weight_g'\n",
    "    ] = median_weight_cama_mesa_banho\n",
    "    \n",
    "    print(f\"\\nO peso dos 4 produtos da categoria 'cama_mesa_banho' que eram zero foi atualizado para: {median_weight_cama_mesa_banho}g\")\n",
    "else:\n",
    "    print(\"\\nNão foi possível calcular a mediana do peso para 'cama_mesa_banho' (talvez todos os produtos da categoria tivessem peso zero ou a categoria não existe). Nenhuma imputação realizada.\")\n",
    "\n",
    "# 3. Verificar se ainda existem produtos com peso zero\n",
    "num_produtos_peso_zero_depois = products_df[products_df['product_weight_g'] == 0.0]['product_id'].count()\n",
    "print(f\"Número de produtos com product_weight_g == 0.0 DEPOIS da imputação: {num_produtos_peso_zero_depois}\")\n",
    "\n",
    "# Vamos verificar também as informações desses 4 produtos específicos após a alteração\n",
    "# (você pode copiar os product_id da sua saída anterior se quiser ser exato, ou apenas verificar se a contagem de peso zero é 0)\n",
    "# Exemplo com um dos IDs que você me mostrou (adapte se necessário):\n",
    "# print(\"\\nVerificando um dos produtos atualizados:\")\n",
    "# print(products_df[products_df['product_id'] == '81781c0fed9fe1ad6e8c81fca1e1cb08'][['product_category_name', 'product_weight_g']])\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b662e9ca-9bbe-410d-8a72-8734756c3230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transações de pagamento com payment_value == 0.0: 9\n",
      "\n",
      "Alguns exemplos de pagamentos com valor zero:\n",
      "                               order_id  payment_sequential payment_type  \\\n",
      "19922  8bcbe01d44d147f901cd3192671144db                   4      voucher   \n",
      "36822  fa65dad1b0e818e3ccc5cb0e39231352                  14      voucher   \n",
      "43744  6ccb433e00daae1283ccc956189c82ae                   4      voucher   \n",
      "51280  4637ca194b6387e2d538dc89b124b0ee                   1  not_defined   \n",
      "57411  00b1cb0320190ca0daa2c88b35206009                   1  not_defined   \n",
      "\n",
      "       payment_installments  payment_value  \n",
      "19922                     1            0.0  \n",
      "36822                     1            0.0  \n",
      "43744                     1            0.0  \n",
      "51280                     1            0.0  \n",
      "57411                     1            0.0  \n",
      "\n",
      "Tipos de pagamento para transações com valor zero:\n",
      "payment_type\n",
      "voucher        6\n",
      "not_defined    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Número de parcelas para transações com valor zero:\n",
      "payment_installments\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Adicione esta linha se ainda não importou pandas neste notebook\n",
    "import os # Adicione esta linha se ainda não importou os neste notebook\n",
    "\n",
    "# Caminho base para os dados (se não definido antes no notebook)\n",
    "# data_path = 'dados/' # Descomente se necessário\n",
    "\n",
    "# Carregar o dataset de pagamentos (se ainda não estiver carregado no notebook)\n",
    "order_payments_df = pd.read_csv(os.path.join(data_path, 'olist_order_payments_dataset.csv')) # <--- LINHA DESCOMENTADA\n",
    "\n",
    "# Filtrar pagamentos com valor igual a zero\n",
    "pagamentos_valor_zero_df = order_payments_df[order_payments_df['payment_value'] == 0.0]\n",
    "num_pagamentos_valor_zero = len(pagamentos_valor_zero_df)\n",
    "\n",
    "print(f\"Número de transações de pagamento com payment_value == 0.0: {num_pagamentos_valor_zero}\")\n",
    "\n",
    "# Se houver pagamentos com valor zero, vamos dar uma olhada neles\n",
    "if num_pagamentos_valor_zero > 0:\n",
    "    print(\"\\nAlguns exemplos de pagamentos com valor zero:\")\n",
    "    print(pagamentos_valor_zero_df.head())\n",
    "    \n",
    "    print(\"\\nTipos de pagamento para transações com valor zero:\")\n",
    "    print(pagamentos_valor_zero_df['payment_type'].value_counts())\n",
    "    \n",
    "    print(\"\\nNúmero de parcelas para transações com valor zero:\")\n",
    "    print(pagamentos_valor_zero_df['payment_installments'].value_counts())\n",
    "else:\n",
    "    print(\"Nenhuma transação de pagamento com valor zero encontrada!\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050ffa78-0183-45fb-bfbc-afbec0a0e1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order IDs com pagamento 'not_defined' e valor R$0.00: ['4637ca194b6387e2d538dc89b124b0ee', '00b1cb0320190ca0daa2c88b35206009', 'c8c528189310eaa44a745b8d9d26908b']\n",
      "Número de pedidos únicos afetados: 3\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Detalhes de todas as transações de pagamento para os pedidos afetados:\n",
      "                               order_id  payment_sequential payment_type  \\\n",
      "51280  4637ca194b6387e2d538dc89b124b0ee                   1  not_defined   \n",
      "57411  00b1cb0320190ca0daa2c88b35206009                   1  not_defined   \n",
      "94427  c8c528189310eaa44a745b8d9d26908b                   1  not_defined   \n",
      "\n",
      "       payment_installments  payment_value  \n",
      "51280                     1            0.0  \n",
      "57411                     1            0.0  \n",
      "94427                     1            0.0  \n"
     ]
    }
   ],
   "source": [
    "# 1. Identificar os order_ids que têm transações com payment_type 'not_defined' E payment_value 0.0\n",
    "orders_com_pagamento_estranho = order_payments_df[\n",
    "    (order_payments_df['payment_type'] == 'not_defined') & \n",
    "    (order_payments_df['payment_value'] == 0.0)\n",
    "]['order_id'].unique() # .unique() para pegar cada order_id apenas uma vez\n",
    "\n",
    "print(f\"Order IDs com pagamento 'not_defined' e valor R$0.00: {list(orders_com_pagamento_estranho)}\")\n",
    "print(f\"Número de pedidos únicos afetados: {len(orders_com_pagamento_estranho)}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# 2. Exibir TODAS as transações de pagamento para ESSES order_ids específicos\n",
    "if len(orders_com_pagamento_estranho) > 0:\n",
    "    print(\"Detalhes de todas as transações de pagamento para os pedidos afetados:\")\n",
    "    pagamentos_pedidos_afetados_df = order_payments_df[\n",
    "        order_payments_df['order_id'].isin(orders_com_pagamento_estranho)\n",
    "    ]\n",
    "    print(pagamentos_pedidos_afetados_df)\n",
    "else:\n",
    "    print(\"Nenhum pedido encontrado com pagamento 'not_defined' e valor zero (talvez já tenham sido tratados ou não existem).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828a258c-a696-4f58-b248-0e7a39fb7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas em order_payments_df ANTES da remoção: 103886\n",
      "\n",
      "Serão removidas 3 linhas com payment_type='not_defined' e payment_value=0.0.\n",
      "Número de linhas em order_payments_df DEPOIS da remoção: 103883\n",
      "Número de pagamentos 'not_defined' com valor zero DEPOIS da remoção: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Antes de remover, vamos confirmar o número de linhas original\n",
    "print(f\"Número de linhas em order_payments_df ANTES da remoção: {len(order_payments_df)}\")\n",
    "\n",
    "# Identificar os índices das linhas onde payment_type é 'not_defined' E payment_value é 0.0\n",
    "indices_para_remover = order_payments_df[\n",
    "    (order_payments_df['payment_type'] == 'not_defined') & \n",
    "    (order_payments_df['payment_value'] == 0.0)\n",
    "].index\n",
    "\n",
    "print(f\"\\nSerão removidas {len(indices_para_remover)} linhas com payment_type='not_defined' e payment_value=0.0.\")\n",
    "\n",
    "# Remover as linhas identificadas.\n",
    "# Usamos .drop() e passamos os índices. axis=0 indica que estamos removendo linhas.\n",
    "# Criaremos um novo DataFrame para não modificar o original diretamente até termos certeza.\n",
    "order_payments_df_limpo = order_payments_df.drop(indices_para_remover)\n",
    "\n",
    "print(f\"Número de linhas em order_payments_df DEPOIS da remoção: {len(order_payments_df_limpo)}\")\n",
    "\n",
    "# Verificar se ainda existem pagamentos 'not_defined' com valor zero no DataFrame limpo\n",
    "pagamentos_not_defined_zero_depois = order_payments_df_limpo[\n",
    "    (order_payments_df_limpo['payment_type'] == 'not_defined') & \n",
    "    (order_payments_df_limpo['payment_value'] == 0.0)\n",
    "]\n",
    "print(f\"Número de pagamentos 'not_defined' com valor zero DEPOIS da remoção: {len(pagamentos_not_defined_zero_depois)}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Se você estiver satisfeito com a remoção, pode reatribuir o DataFrame limpo\n",
    "# ao nome original para continuar trabalhando com ele nos próximos passos:\n",
    "# order_payments_df = order_payments_df_limpo\n",
    "# print(\"DataFrame 'order_payments_df' atualizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0bdf0e7-132d-496d-85eb-f76f67483ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'order_payments_df' foi atualizado.\n",
      "Número atual de linhas em order_payments_df: 103883\n",
      "Verificando novamente se há pagamentos 'not_defined' com valor zero: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que 'order_payments_df_limpo' existe da etapa anterior\n",
    "# onde removemos as 3 linhas.\n",
    "\n",
    "# Atualizar order_payments_df para refletir a remoção das 3 linhas\n",
    "order_payments_df = order_payments_df_limpo \n",
    "\n",
    "# Agora vamos imprimir informações sobre o DataFrame atualizado\n",
    "print(\"DataFrame 'order_payments_df' foi atualizado.\")\n",
    "print(f\"Número atual de linhas em order_payments_df: {len(order_payments_df)}\")\n",
    "print(f\"Verificando novamente se há pagamentos 'not_defined' com valor zero: {len(order_payments_df[(order_payments_df['payment_type'] == 'not_defined') & (order_payments_df['payment_value'] == 0.0)])}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de14dc01-2268-4580-8779-f183fe0ccd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de transações de pagamento com payment_installments == 0: 2\n",
      "\n",
      "Tipos de pagamento para transações com zero parcelas:\n",
      "payment_type\n",
      "credit_card    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estatísticas do valor de pagamento para transações com zero parcelas:\n",
      "count      2.000000\n",
      "mean      94.315000\n",
      "std       50.381358\n",
      "min       58.690000\n",
      "25%       76.502500\n",
      "50%       94.315000\n",
      "75%      112.127500\n",
      "max      129.940000\n",
      "Name: payment_value, dtype: float64\n",
      "\n",
      "Exemplos de transações com zero parcelas (primeiras 5 linhas):\n",
      "                               order_id  payment_sequential payment_type  \\\n",
      "46982  744bade1fcf9ff3f31d860ace076d422                   2  credit_card   \n",
      "79014  1a57108394169c0b47d8f876acc9ba2d                   2  credit_card   \n",
      "\n",
      "       payment_installments  payment_value  \n",
      "46982                     0          58.69  \n",
      "79014                     0         129.94  \n",
      "\n",
      "Número de transações \"credit_card\" com zero parcelas: 2\n",
      "Exemplos de 'credit_card' com zero parcelas:\n",
      "                               order_id  payment_sequential payment_type  \\\n",
      "46982  744bade1fcf9ff3f31d860ace076d422                   2  credit_card   \n",
      "79014  1a57108394169c0b47d8f876acc9ba2d                   2  credit_card   \n",
      "\n",
      "       payment_installments  payment_value  \n",
      "46982                     0          58.69  \n",
      "79014                     0         129.94  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar pagamentos com zero parcelas usando o order_payments_df atualizado\n",
    "pagamentos_zero_parcelas_df = order_payments_df[order_payments_df['payment_installments'] == 0]\n",
    "num_pagamentos_zero_parcelas = len(pagamentos_zero_parcelas_df)\n",
    "\n",
    "print(f\"Número de transações de pagamento com payment_installments == 0: {num_pagamentos_zero_parcelas}\")\n",
    "\n",
    "# Se houver pagamentos com zero parcelas, vamos analisá-los\n",
    "if num_pagamentos_zero_parcelas > 0:\n",
    "    print(\"\\nTipos de pagamento para transações com zero parcelas:\")\n",
    "    print(pagamentos_zero_parcelas_df['payment_type'].value_counts())\n",
    "    \n",
    "    print(\"\\nEstatísticas do valor de pagamento para transações com zero parcelas:\")\n",
    "    print(pagamentos_zero_parcelas_df['payment_value'].describe())\n",
    "    \n",
    "    print(\"\\nExemplos de transações com zero parcelas (primeiras 5 linhas):\")\n",
    "    print(pagamentos_zero_parcelas_df.head())\n",
    "    \n",
    "    # Adicionar uma verificação específica para cartão de crédito com 0 parcelas\n",
    "    cartao_credito_zero_parcelas = pagamentos_zero_parcelas_df[\n",
    "        pagamentos_zero_parcelas_df['payment_type'] == 'credit_card'\n",
    "    ]\n",
    "    # Linha modificada abaixo:\n",
    "    print(f\"\\nNúmero de transações \\\"credit_card\\\" com zero parcelas: {len(cartao_credito_zero_parcelas)}\") \n",
    "    \n",
    "    if len(cartao_credito_zero_parcelas) > 0:\n",
    "        print(\"Exemplos de 'credit_card' com zero parcelas:\")\n",
    "        print(cartao_credito_zero_parcelas.head())\n",
    "else:\n",
    "    print(\"Nenhuma transação de pagamento com zero parcelas encontrada!\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d118e2b-e26b-444c-b177-cb3f5c8ee176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detalhes de TODAS as transações de pagamento para os pedidos investigados:\n",
      "                               order_id  payment_sequential payment_type  \\\n",
      "79014  1a57108394169c0b47d8f876acc9ba2d                   2  credit_card   \n",
      "46982  744bade1fcf9ff3f31d860ace076d422                   2  credit_card   \n",
      "\n",
      "       payment_installments  payment_value  \n",
      "79014                     0         129.94  \n",
      "46982                     0          58.69  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IDs dos pedidos que tiveram transação 'credit_card' com 0 parcelas\n",
    "order_ids_para_investigar = ['744bade1fcf9ff3f31d860ace076d422', '1a57108394169c0b47d8f876acc9ba2d']\n",
    "\n",
    "print(\"Detalhes de TODAS as transações de pagamento para os pedidos investigados:\")\n",
    "# Filtramos o DataFrame de pagamentos para os order_ids específicos\n",
    "# e ordenamos para facilitar a leitura das sequências de pagamento\n",
    "info_pagamentos_pedidos_investigados = order_payments_df[\n",
    "    order_payments_df['order_id'].isin(order_ids_para_investigar)\n",
    "].sort_values(by=['order_id', 'payment_sequential'])\n",
    "\n",
    "print(info_pagamentos_pedidos_investigados)\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "181b46f3-2e40-4404-88aa-1df96d344432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parcelas corrigidas para 1 nas 2 transações 'credit_card' que tinham 0 parcelas.\n"
     ]
    }
   ],
   "source": [
    "# Condição para selecionar as 2 linhas específicas\n",
    "condicao_correcao_parcelas = (order_payments_df['payment_installments'] == 0) & \\\n",
    "                           (order_payments_df['payment_type'] == 'credit_card')\n",
    "\n",
    "# Alterar payment_installments para 1 nessas linhas\n",
    "order_payments_df.loc[condicao_correcao_parcelas, 'payment_installments'] = 1\n",
    "\n",
    "print(\"Parcelas corrigidas para 1 nas 2 transações 'credit_card' que tinham 0 parcelas.\")\n",
    "\n",
    "# Verificar novamente (opcional, mas bom para confirmar)\n",
    "# print(order_payments_df[order_payments_df['order_id'].isin(order_ids_para_investigar)].sort_values(by=['order_id', 'payment_sequential']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ceabae-c8ae-41b1-8c1b-731027cc4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de order_id únicos na tabela 'orders_df': 99441\n",
      "Número de order_id únicos na tabela 'order_items_df': 98666\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Número de pedidos em 'orders_df' que não possuem itens em 'order_items_df': 775\n",
      "\n",
      "Analisando o status desses pedidos sem itens (primeiros 5 exemplos):\n",
      "                              order_id order_status\n",
      "266   8e24261a7e58791d10cb1bf9da94df5c  unavailable\n",
      "586   c272bcd21c287498b4883c7512019702  unavailable\n",
      "687   37553832a3a89c9b2db59701c357ca67  unavailable\n",
      "737   d57e15fb07fd180f06ab3926b39edcd2  unavailable\n",
      "1130  00b1cb0320190ca0daa2c88b35206009     canceled\n",
      "\n",
      "Contagem de status para os pedidos sem itens:\n",
      "order_status\n",
      "unavailable    603\n",
      "canceled       164\n",
      "created          5\n",
      "invoiced         2\n",
      "shipped          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Número de order_id em 'order_items_df' que não existem em 'orders_df': 0\n",
      "Verificação de integridade: Todos os itens em 'order_items_df' correspondem a um pedido em 'orders_df'.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que orders_df e order_items_df estão carregados e atualizados\n",
    "# (já fizemos a conversão de datas neles)\n",
    "\n",
    "# Obter os conjuntos de order_id únicos de cada DataFrame\n",
    "ids_unicos_em_orders = set(orders_df['order_id'].unique())\n",
    "ids_unicos_em_order_items = set(order_items_df['order_id'].unique())\n",
    "\n",
    "print(f\"Número de order_id únicos na tabela 'orders_df': {len(ids_unicos_em_orders)}\")\n",
    "print(f\"Número de order_id únicos na tabela 'order_items_df': {len(ids_unicos_em_order_items)}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# 1. Verificar quais order_id estão em 'orders_df' mas NÃO em 'order_items_df'\n",
    "# (Ou seja, pedidos que não têm nenhum item listado)\n",
    "pedidos_sem_itens_registrados = ids_unicos_em_orders - ids_unicos_em_order_items\n",
    "num_pedidos_sem_itens = len(pedidos_sem_itens_registrados)\n",
    "\n",
    "print(f\"Número de pedidos em 'orders_df' que não possuem itens em 'order_items_df': {num_pedidos_sem_itens}\")\n",
    "\n",
    "# Se houver pedidos sem itens, vamos investigar o status deles\n",
    "if num_pedidos_sem_itens > 0:\n",
    "    print(\"\\nAnalisando o status desses pedidos sem itens (primeiros 5 exemplos):\")\n",
    "    # Filtramos o orders_df para pegar apenas esses pedidos\n",
    "    df_pedidos_sem_itens = orders_df[orders_df['order_id'].isin(list(pedidos_sem_itens_registrados))]\n",
    "    print(df_pedidos_sem_itens[['order_id', 'order_status']].head())\n",
    "    print(\"\\nContagem de status para os pedidos sem itens:\")\n",
    "    print(df_pedidos_sem_itens['order_status'].value_counts())\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# 2. Verificar quais order_id estão em 'order_items_df' mas NÃO em 'orders_df'\n",
    "# (Isso seria um problema de integridade referencial - itens de um pedido que não existe)\n",
    "itens_sem_pedido_correspondente = ids_unicos_em_order_items - ids_unicos_em_orders\n",
    "num_itens_sem_pedido_correspondente = len(itens_sem_pedido_correspondente)\n",
    "\n",
    "print(f\"Número de order_id em 'order_items_df' que não existem em 'orders_df': {num_itens_sem_pedido_correspondente}\")\n",
    "\n",
    "if num_itens_sem_pedido_correspondente > 0:\n",
    "    print(\"ATENÇÃO: Foram encontrados itens de pedidos que não existem na tabela de pedidos!\")\n",
    "    print(\"Exemplos de order_id problemáticos (primeiros 5):\")\n",
    "    print(list(itens_sem_pedido_correspondente)[:5])\n",
    "else:\n",
    "    print(\"Verificação de integridade: Todos os itens em 'order_items_df' correspondem a um pedido em 'orders_df'.\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62e50b26-b828-4f78-9e3c-46506d77d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de categorias únicas em products_df: 74\n",
      "Número de categorias com tradução (PT): 71\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Categorias em products_df que não têm tradução em category_translation_df (3):\n",
      "- portateis_cozinha_e_preparadores_de_alimentos\n",
      "- desconhecida\n",
      "- pc_gamer\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Garanta que o pandas está importado\n",
    "import os # Garanta que o os está importado\n",
    "\n",
    "# Caminho base para os dados (se não definido antes no notebook)\n",
    "# data_path = 'dados/' # Descomente se necessário\n",
    "\n",
    "# Certifique-se de que products_df está carregado e limpo\n",
    "# products_df já foi limpo (NaNs de categoria preenchidos com \"desconhecida\").\n",
    "\n",
    "# Carregar o category_translation_df\n",
    "category_translation_df = pd.read_csv(os.path.join(data_path, 'product_category_name_translation.csv')) # <-- LINHA ADICIONADA/CORRIGIDA\n",
    "\n",
    "# Obter nomes de categoria únicos de products_df\n",
    "categorias_em_products = set(products_df['product_category_name'].unique())\n",
    "\n",
    "# Obter nomes de categoria únicos (em português) de category_translation_df\n",
    "categorias_com_traducao_pt = set(category_translation_df['product_category_name'].unique())\n",
    "\n",
    "print(f\"Número de categorias únicas em products_df: {len(categorias_em_products)}\")\n",
    "print(f\"Número de categorias com tradução (PT): {len(categorias_com_traducao_pt)}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Identificar categorias em products_df que NÃO estão no arquivo de tradução\n",
    "categorias_sem_traducao = categorias_em_products - categorias_com_traducao_pt\n",
    "print(f\"Categorias em products_df que não têm tradução em category_translation_df ({len(categorias_sem_traducao)}):\")\n",
    "if len(categorias_sem_traducao) > 0:\n",
    "    for cat in categorias_sem_traducao:\n",
    "        print(f\"- {cat}\")\n",
    "else:\n",
    "    print(\"Todas as categorias em products_df têm uma entrada no arquivo de tradução (ou não há categorias).\")\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a72e7ac-8b6f-4865-b389-58915150884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products_df após o merge (visualizando as colunas de categoria):\n",
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "  product_category_name_english  \n",
      "0                     perfumery  \n",
      "1                           art  \n",
      "2                sports_leisure  \n",
      "3                          baby  \n",
      "4                    housewares  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Valores ausentes em 'product_category_name_english' após o merge: 623\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Valores ausentes em 'product_category_name_english' APÓS preenchimento manual: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Verificando as traduções aplicadas para as categorias tratadas manualmente:\n",
      "                              product_category_name  \\\n",
      "105                                    desconhecida   \n",
      "1628                                       pc_gamer   \n",
      "5821  portateis_cozinha_e_preparadores_de_alimentos   \n",
      "\n",
      "     product_category_name_english  \n",
      "105                        unknown  \n",
      "1628                     gaming_pc  \n",
      "5821   kitchen_portables_food_prep  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Informações do products_df após adicionar e preencher a tradução da categoria:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   product_id                     32951 non-null  object \n",
      " 1   product_category_name          32951 non-null  object \n",
      " 2   product_name_lenght            32951 non-null  float64\n",
      " 3   product_description_lenght     32951 non-null  float64\n",
      " 4   product_photos_qty             32951 non-null  float64\n",
      " 5   product_weight_g               32951 non-null  float64\n",
      " 6   product_length_cm              32951 non-null  float64\n",
      " 7   product_height_cm              32951 non-null  float64\n",
      " 8   product_width_cm               32951 non-null  float64\n",
      " 9   product_category_name_english  32951 non-null  object \n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Fazer o merge de products_df com category_translation_df\n",
    "# Usaremos um 'left merge' para garantir que todos os produtos de products_df sejam mantidos.\n",
    "# A junção será feita pela coluna 'product_category_name'.\n",
    "products_df = pd.merge(\n",
    "    products_df,\n",
    "    category_translation_df,\n",
    "    on='product_category_name',  # Coluna chave para o merge\n",
    "    how='left'                   # Tipo de merge: 'left' mantém todas as linhas de products_df\n",
    ")\n",
    "\n",
    "# Verificar as primeiras linhas para ver a nova coluna 'product_category_name_english'\n",
    "print(\"Products_df após o merge (visualizando as colunas de categoria):\")\n",
    "print(products_df[['product_id', 'product_category_name', 'product_category_name_english']].head())\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Verificar quantos valores ficaram ausentes (NaN) em 'product_category_name_english'\n",
    "# Estes serão os correspondentes às nossas 3 categorias não traduzidas.\n",
    "print(f\"Valores ausentes em 'product_category_name_english' após o merge: {products_df['product_category_name_english'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# 2. Preencher os NaNs na coluna 'product_category_name_english' para as categorias específicas\n",
    "\n",
    "# Para a categoria 'desconhecida' que criamos\n",
    "products_df.loc[products_df['product_category_name'] == 'desconhecida', 'product_category_name_english'] = 'unknown'\n",
    "\n",
    "# Para 'pc_gamer', podemos usar 'gaming_pc' ou manter 'pc_gamer' que é bem entendido\n",
    "products_df.loc[products_df['product_category_name'] == 'pc_gamer', 'product_category_name_english'] = 'gaming_pc'\n",
    "\n",
    "# Para 'portateis_cozinha_e_preparadores_de_alimentos', podemos usar uma tradução aproximada ou um placeholder.\n",
    "# Vou sugerir uma tradução curta e funcional:\n",
    "products_df.loc[products_df['product_category_name'] == 'portateis_cozinha_e_preparadores_de_alimentos', 'product_category_name_english'] = 'kitchen_portables_food_prep'\n",
    "\n",
    "\n",
    "# Verificar novamente se ainda há valores ausentes em 'product_category_name_english'\n",
    "print(f\"Valores ausentes em 'product_category_name_english' APÓS preenchimento manual: {products_df['product_category_name_english'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Vamos dar uma olhada nas traduções para as categorias que tratamos manualmente\n",
    "categorias_tratadas_manualmente = ['desconhecida', 'pc_gamer', 'portateis_cozinha_e_preparadores_de_alimentos']\n",
    "print(\"Verificando as traduções aplicadas para as categorias tratadas manualmente:\")\n",
    "print(products_df[products_df['product_category_name'].isin(categorias_tratadas_manualmente)]\n",
    "      [['product_category_name', 'product_category_name_english']].drop_duplicates()) # .drop_duplicates() para ver cada par uma vez\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Finalmente, vamos ver as informações gerais do products_df atualizado\n",
    "print(\"Informações do products_df após adicionar e preencher a tradução da categoria:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31fd8206-fcf8-401f-866a-d00e34887261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de orders_df: (99441, 8)\n",
      "Dimensões de order_items_df: (112650, 7)\n",
      "\n",
      "Dimensões do df_merged após juntar orders_df e order_items_df: (112650, 14)\n",
      "\n",
      "Primeiras linhas do df_merged:\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06 2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39 2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  order_item_id  \\\n",
      "0                    2017-10-18              1   \n",
      "1                    2018-08-13              1   \n",
      "2                    2018-09-04              1   \n",
      "3                    2017-12-15              1   \n",
      "4                    2018-02-26              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  87285b34884572647811a353c7ac498a  3504c0cb71d7fa48d967e0e4c94d59d9   \n",
      "1  595fac2a385ac33a80bd5114aec74eb8  289cdb325fb7e7f891c38608bf9e0962   \n",
      "2  aa4383b373c6aca5d8797843e5594415  4869f7a5dfa277a7dca6462dcf3b52b2   \n",
      "3  d0b61bfb1de832b15ba9d266ca96e5b0  66922902710d126a0e7d26b0e3805106   \n",
      "4  65266b2da20d04dbe00c5c2d3bb7859e  2c9e548be18521d1c43cde1c582c6de8   \n",
      "\n",
      "  shipping_limit_date   price  freight_value  \n",
      "0 2017-10-06 11:07:15   29.99           8.72  \n",
      "1 2018-07-30 03:24:27  118.70          22.76  \n",
      "2 2018-08-13 08:55:23  159.90          19.22  \n",
      "3 2017-11-23 19:45:59   45.00          27.20  \n",
      "4 2018-02-19 20:31:37   19.90           8.72  \n",
      "\n",
      "Informações do df_merged:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 14 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      "dtypes: datetime64[ns](6), float64(2), int64(1), object(5)\n",
      "memory usage: 12.0+ MB\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que os DataFrames orders_df e order_items_df estão carregados\n",
    "# e com as limpezas que já fizemos (principalmente conversões de data).\n",
    "\n",
    "# Relembrando as dimensões\n",
    "print(f\"Dimensões de orders_df: {orders_df.shape}\")\n",
    "print(f\"Dimensões de order_items_df: {order_items_df.shape}\")\n",
    "\n",
    "# Fazer a junção (merge)\n",
    "# Usaremos um 'inner' merge. Isso significa que apenas os order_id que existem\n",
    "# em AMBAS as tabelas serão mantidos no resultado. Como já vimos, existem\n",
    "# pedidos em orders_df que não têm itens (ex: cancelados). Um 'inner' merge\n",
    "# focará nos pedidos que efetivamente tiveram itens.\n",
    "df_merged = pd.merge(\n",
    "    orders_df,\n",
    "    order_items_df,\n",
    "    on='order_id',  # Coluna chave para a junção\n",
    "    how='inner'     # Tipo de junção\n",
    ")\n",
    "\n",
    "# Verificar as dimensões do DataFrame resultante\n",
    "print(f\"\\nDimensões do df_merged após juntar orders_df e order_items_df: {df_merged.shape}\")\n",
    "\n",
    "# Exibir as primeiras linhas e informações do DataFrame mesclado\n",
    "print(\"\\nPrimeiras linhas do df_merged:\")\n",
    "print(df_merged.head())\n",
    "\n",
    "print(\"\\nInformações do df_merged:\")\n",
    "df_merged.info()\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fdd9472-20ad-406e-9683-a19ef2602340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de df_merged (atual): (112650, 14)\n",
      "Dimensões de products_df: (32951, 10)\n",
      "\n",
      "Dimensões do df_merged após juntar com products_df: (112650, 23)\n",
      "\n",
      "Primeiras linhas do df_merged (com info de produtos):\n",
      "                           order_id                        product_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  87285b34884572647811a353c7ac498a   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  595fac2a385ac33a80bd5114aec74eb8   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  aa4383b373c6aca5d8797843e5594415   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  d0b61bfb1de832b15ba9d266ca96e5b0   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  65266b2da20d04dbe00c5c2d3bb7859e   \n",
      "\n",
      "   product_category_name product_category_name_english   price  \n",
      "0  utilidades_domesticas                    housewares   29.99  \n",
      "1             perfumaria                     perfumery  118.70  \n",
      "2             automotivo                          auto  159.90  \n",
      "3               pet_shop                      pet_shop   45.00  \n",
      "4              papelaria                    stationery   19.90  \n",
      "\n",
      "Informações do df_merged (com info de produtos):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 23 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      " 14  product_category_name          112650 non-null  object        \n",
      " 15  product_name_lenght            112650 non-null  float64       \n",
      " 16  product_description_lenght     112650 non-null  float64       \n",
      " 17  product_photos_qty             112650 non-null  float64       \n",
      " 18  product_weight_g               112650 non-null  float64       \n",
      " 19  product_length_cm              112650 non-null  float64       \n",
      " 20  product_height_cm              112650 non-null  float64       \n",
      " 21  product_width_cm               112650 non-null  float64       \n",
      " 22  product_category_name_english  112650 non-null  object        \n",
      "dtypes: datetime64[ns](6), float64(9), int64(1), object(7)\n",
      "memory usage: 19.8+ MB\n",
      "\n",
      "Número de NaNs em 'product_category_name' após merge com products_df: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que products_df está carregado e com as limpezas que já fizemos\n",
    "# (categoria \"desconhecida\", tratamento de NaNs, peso zero corrigido, e a coluna de tradução).\n",
    "\n",
    "# Relembrando as dimensões\n",
    "print(f\"Dimensões de df_merged (atual): {df_merged.shape}\")\n",
    "print(f\"Dimensões de products_df: {products_df.shape}\")\n",
    "\n",
    "# Fazer a junção (merge)\n",
    "# Usaremos um 'left' merge a partir de df_merged.\n",
    "# Isso garante que todos os itens de pedido em df_merged sejam mantidos.\n",
    "# Se um product_id em df_merged não for encontrado em products_df (o que seria um problema de integridade),\n",
    "# as colunas de products_df virão como NaN para essa linha.\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    products_df,\n",
    "    on='product_id', # Coluna chave para a junção\n",
    "    how='left'       # Tipo de junção\n",
    ")\n",
    "\n",
    "# Verificar as dimensões do DataFrame resultante\n",
    "print(f\"\\nDimensões do df_merged após juntar com products_df: {df_merged.shape}\")\n",
    "\n",
    "# Exibir as primeiras linhas e informações do DataFrame mesclado\n",
    "print(\"\\nPrimeiras linhas do df_merged (com info de produtos):\")\n",
    "# Vamos selecionar algumas colunas chave para visualização\n",
    "cols_to_show = ['order_id', 'product_id', 'product_category_name', 'product_category_name_english', 'price']\n",
    "print(df_merged[cols_to_show].head())\n",
    "\n",
    "print(\"\\nInformações do df_merged (com info de produtos):\")\n",
    "df_merged.info()\n",
    "\n",
    "# Verificar se algum product_id não encontrou correspondência (resultando em NaNs nas colunas de produto)\n",
    "# Por exemplo, verificando NaNs em 'product_category_name', que é uma coluna de products_df\n",
    "# (já tratamos NaNs em products_df, então qualquer NaN aqui viria de um merge sem correspondência)\n",
    "print(f\"\\nNúmero de NaNs em 'product_category_name' após merge com products_df: {df_merged['product_category_name'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f549c26-264b-4303-928c-7c0e2770a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de df_merged (atual): (112650, 23)\n",
      "Dimensões de customers_df: (99441, 5)\n",
      "\n",
      "Dimensões do df_merged após juntar com customers_df: (112650, 27)\n",
      "\n",
      "Primeiras linhas do df_merged (com info de clientes):\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "                 customer_unique_id            customer_city customer_state  \\\n",
      "0  7c396fd4830fd04220f754e42b4e5bff                sao paulo             SP   \n",
      "1  af07308b275d755c9edb36a90c618231                barreiras             BA   \n",
      "2  3a653a41f6f9fc3d2a113cf8398680e8               vianopolis             GO   \n",
      "3  7c142cf63193a1473d2e66489a9ae977  sao goncalo do amarante             RN   \n",
      "4  72632f0f9dd73dfee390c9b22eb56dd6              santo andre             SP   \n",
      "\n",
      "    price  \n",
      "0   29.99  \n",
      "1  118.70  \n",
      "2  159.90  \n",
      "3   45.00  \n",
      "4   19.90  \n",
      "\n",
      "Informações do df_merged (com info de clientes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 27 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      " 14  product_category_name          112650 non-null  object        \n",
      " 15  product_name_lenght            112650 non-null  float64       \n",
      " 16  product_description_lenght     112650 non-null  float64       \n",
      " 17  product_photos_qty             112650 non-null  float64       \n",
      " 18  product_weight_g               112650 non-null  float64       \n",
      " 19  product_length_cm              112650 non-null  float64       \n",
      " 20  product_height_cm              112650 non-null  float64       \n",
      " 21  product_width_cm               112650 non-null  float64       \n",
      " 22  product_category_name_english  112650 non-null  object        \n",
      " 23  customer_unique_id             112650 non-null  object        \n",
      " 24  customer_zip_code_prefix       112650 non-null  int64         \n",
      " 25  customer_city                  112650 non-null  object        \n",
      " 26  customer_state                 112650 non-null  object        \n",
      "dtypes: datetime64[ns](6), float64(9), int64(2), object(10)\n",
      "memory usage: 23.2+ MB\n",
      "\n",
      "Número de NaNs em 'customer_unique_id' após merge com customers_df: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Garanta que o pandas está importado\n",
    "import os # Garanta que o os está importado\n",
    "\n",
    "# Caminho base para os dados (se não definido antes no notebook)\n",
    "# data_path = 'dados/' # Descomente se necessário\n",
    "\n",
    "# Certifique-se de que df_merged está como o resultado dos merges anteriores.\n",
    "\n",
    "# Carregar o customers_df\n",
    "customers_df = pd.read_csv(os.path.join(data_path, 'olist_customers_dataset.csv')) # <-- LINHA DESCOMENTADA\n",
    "\n",
    "# Relembrando as dimensões\n",
    "print(f\"Dimensões de df_merged (atual): {df_merged.shape}\")\n",
    "print(f\"Dimensões de customers_df: {customers_df.shape}\")\n",
    "\n",
    "# Fazer a junção (merge)\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    customers_df,\n",
    "    on='customer_id', # Coluna chave para a junção\n",
    "    how='left'        # Tipo de junção\n",
    ")\n",
    "\n",
    "# Verificar as dimensões do DataFrame resultante\n",
    "print(f\"\\nDimensões do df_merged após juntar com customers_df: {df_merged.shape}\")\n",
    "\n",
    "# Exibir as primeiras linhas e informações do DataFrame mesclado\n",
    "print(\"\\nPrimeiras linhas do df_merged (com info de clientes):\")\n",
    "cols_to_show = ['order_id', 'customer_id', 'customer_unique_id', 'customer_city', 'customer_state', 'price']\n",
    "print(df_merged[cols_to_show].head())\n",
    "\n",
    "print(\"\\nInformações do df_merged (com info de clientes):\")\n",
    "df_merged.info()\n",
    "\n",
    "# Verificar se algum customer_id não encontrou correspondência\n",
    "print(f\"\\nNúmero de NaNs em 'customer_unique_id' após merge com customers_df: {df_merged['customer_unique_id'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e020cbf9-9222-4c52-9abe-8bf92012e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de df_merged (atual): (112650, 27)\n",
      "Dimensões de sellers_df: (3095, 4)\n",
      "\n",
      "Dimensões do df_merged após juntar com sellers_df: (112650, 30)\n",
      "\n",
      "Primeiras linhas do df_merged (com info de vendedores):\n",
      "                           order_id                        product_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  87285b34884572647811a353c7ac498a   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  595fac2a385ac33a80bd5114aec74eb8   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  aa4383b373c6aca5d8797843e5594415   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  d0b61bfb1de832b15ba9d266ca96e5b0   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  65266b2da20d04dbe00c5c2d3bb7859e   \n",
      "\n",
      "                          seller_id      seller_city seller_state   price  \n",
      "0  3504c0cb71d7fa48d967e0e4c94d59d9             maua           SP   29.99  \n",
      "1  289cdb325fb7e7f891c38608bf9e0962   belo horizonte           SP  118.70  \n",
      "2  4869f7a5dfa277a7dca6462dcf3b52b2          guariba           SP  159.90  \n",
      "3  66922902710d126a0e7d26b0e3805106   belo horizonte           MG   45.00  \n",
      "4  2c9e548be18521d1c43cde1c582c6de8  mogi das cruzes           SP   19.90  \n",
      "\n",
      "Informações do df_merged (com info de vendedores):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 30 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      " 14  product_category_name          112650 non-null  object        \n",
      " 15  product_name_lenght            112650 non-null  float64       \n",
      " 16  product_description_lenght     112650 non-null  float64       \n",
      " 17  product_photos_qty             112650 non-null  float64       \n",
      " 18  product_weight_g               112650 non-null  float64       \n",
      " 19  product_length_cm              112650 non-null  float64       \n",
      " 20  product_height_cm              112650 non-null  float64       \n",
      " 21  product_width_cm               112650 non-null  float64       \n",
      " 22  product_category_name_english  112650 non-null  object        \n",
      " 23  customer_unique_id             112650 non-null  object        \n",
      " 24  customer_zip_code_prefix       112650 non-null  int64         \n",
      " 25  customer_city                  112650 non-null  object        \n",
      " 26  customer_state                 112650 non-null  object        \n",
      " 27  seller_zip_code_prefix         112650 non-null  int64         \n",
      " 28  seller_city                    112650 non-null  object        \n",
      " 29  seller_state                   112650 non-null  object        \n",
      "dtypes: datetime64[ns](6), float64(9), int64(3), object(12)\n",
      "memory usage: 25.8+ MB\n",
      "\n",
      "Número de NaNs em 'seller_city' (coluna do vendedor) após merge: 0\n",
      "\n",
      "Nomes das colunas no df_merged atualizado:\n",
      "Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
      "       'order_approved_at', 'order_delivered_carrier_date',\n",
      "       'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
      "       'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date',\n",
      "       'price', 'freight_value', 'product_category_name',\n",
      "       'product_name_lenght', 'product_description_lenght',\n",
      "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
      "       'product_height_cm', 'product_width_cm',\n",
      "       'product_category_name_english', 'customer_unique_id',\n",
      "       'customer_zip_code_prefix', 'customer_city', 'customer_state',\n",
      "       'seller_zip_code_prefix', 'seller_city', 'seller_state'],\n",
      "      dtype='object')\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Garanta que o pandas está importado\n",
    "import os # Garanta que o os está importado\n",
    "\n",
    "# Caminho base para os dados (se não definido antes no notebook)\n",
    "# data_path = 'dados/' # Descomente se necessário\n",
    "\n",
    "# Certifique-se de que df_merged está como o resultado dos merges anteriores.\n",
    "\n",
    "# Carregar o sellers_df\n",
    "sellers_df = pd.read_csv(os.path.join(data_path, 'olist_sellers_dataset.csv')) # <-- LINHA DESCOMENTADA\n",
    "\n",
    "# Relembrando as dimensões\n",
    "print(f\"Dimensões de df_merged (atual): {df_merged.shape}\")\n",
    "print(f\"Dimensões de sellers_df: {sellers_df.shape}\")\n",
    "\n",
    "# Fazer a junção (merge)\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    sellers_df,\n",
    "    on='seller_id',  # Coluna chave para a junção\n",
    "    how='left'       # Tipo de junção\n",
    ")\n",
    "\n",
    "# Verificar as dimensões do DataFrame resultante\n",
    "print(f\"\\nDimensões do df_merged após juntar com sellers_df: {df_merged.shape}\")\n",
    "\n",
    "# Exibir as primeiras linhas e informações do DataFrame mesclado\n",
    "print(\"\\nPrimeiras linhas do df_merged (com info de vendedores):\")\n",
    "cols_to_show = ['order_id', 'product_id', 'seller_id', 'seller_city', 'seller_state', 'price']\n",
    "print(df_merged[cols_to_show].head())\n",
    "\n",
    "print(\"\\nInformações do df_merged (com info de vendedores):\")\n",
    "df_merged.info()\n",
    "\n",
    "# Verificar se algum seller_id não encontrou correspondência\n",
    "# As colunas de sellers_df são 'seller_zip_code_prefix', 'seller_city', 'seller_state'.\n",
    "# Vamos verificar NaNs em 'seller_city' (que é uma das colunas adicionadas de sellers_df).\n",
    "print(f\"\\nNúmero de NaNs em 'seller_city' (coluna do vendedor) após merge: {df_merged['seller_city'].isnull().sum()}\")\n",
    "\n",
    "# Mostrar os nomes das colunas para confirmar como ficaram após o merge\n",
    "print(\"\\nNomes das colunas no df_merged atualizado:\")\n",
    "print(df_merged.columns)\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6867c158-9ec1-4594-9c6f-4354a960b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de order_payments_df (limpo): (103883, 5)\n",
      "\n",
      "Dimensões do payments_summary_df (agregado):\n",
      "(99437, 4)\n",
      "\n",
      "Primeiras linhas do payments_summary_df:\n",
      "                           order_id  payment_value_total  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214                72.19   \n",
      "1  00018f77f2f0320c557190d7a144bdd3               259.83   \n",
      "2  000229ec398224ef6ca0657da4fc703e               216.87   \n",
      "3  00024acbcdf0a6daa1e931b038114c75                25.78   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9               218.04   \n",
      "\n",
      "   payment_installments_max  payment_sequential_count  \n",
      "0                         2                         1  \n",
      "1                         3                         1  \n",
      "2                         5                         1  \n",
      "3                         2                         1  \n",
      "4                         3                         1  \n",
      "\n",
      "Informações do payments_summary_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99437 entries, 0 to 99436\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   order_id                  99437 non-null  object \n",
      " 1   payment_value_total       99437 non-null  float64\n",
      " 2   payment_installments_max  99437 non-null  int64  \n",
      " 3   payment_sequential_count  99437 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 3.0+ MB\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que order_payments_df está carregado e com as limpezas que já fizemos.\n",
    "# order_payments_df = pd.read_csv(os.path.join(data_path, 'olist_order_payments_dataset.csv')) # E depois aplicar limpezas se recarregar.\n",
    "# Lembre-se que já limpamos e atualizamos order_payments_df.\n",
    "\n",
    "print(f\"Dimensões de order_payments_df (limpo): {order_payments_df.shape}\")\n",
    "\n",
    "# Agregação dos dados de pagamento\n",
    "payments_summary_df = order_payments_df.groupby('order_id').agg(\n",
    "    payment_value_total=('payment_value', 'sum'),          # Soma total do valor pago por pedido\n",
    "    payment_installments_max=('payment_installments', 'max'), # Máximo de parcelas por pedido\n",
    "    payment_sequential_count=('payment_sequential', 'max'), # Número de transações de pagamento\n",
    "    # Para pegar o tipo de pagamento principal (da primeira transação) ou uma lista:\n",
    "    # Opção 1: Tipo da primeira transação (assumindo que é a principal)\n",
    "    # payment_type_principal=('payment_type', 'first')\n",
    "    # Opção 2: Lista de todos os tipos usados (pode ser mais complexo de usar depois)\n",
    "    # payment_types_list=('payment_type', lambda x: list(x.unique()))\n",
    ").reset_index() # .reset_index() para transformar 'order_id' de volta em uma coluna\n",
    "\n",
    "# Renomear a coluna para o tipo de pagamento (se usou 'first') para clareza\n",
    "# if 'payment_type_principal' in payments_summary_df.columns:\n",
    "#     payments_summary_df.rename(columns={'payment_type_principal': 'main_payment_type'}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"\\nDimensões do payments_summary_df (agregado):\")\n",
    "print(payments_summary_df.shape)\n",
    "print(\"\\nPrimeiras linhas do payments_summary_df:\")\n",
    "print(payments_summary_df.head())\n",
    "print(\"\\nInformações do payments_summary_df:\")\n",
    "payments_summary_df.info()\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c1f6d7-c4c3-4318-adbd-7d1b14e0dddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de df_merged (atual): (112650, 30)\n",
      "\n",
      "Dimensões do df_merged após juntar com payments_summary_df: (112650, 33)\n",
      "\n",
      "Primeiras linhas do df_merged (com info de pagamentos agregados):\n",
      "                           order_id   price  payment_value_total  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7   29.99                38.71   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  118.70               141.46   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  159.90               179.12   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a   45.00                72.20   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159   19.90                28.62   \n",
      "\n",
      "   payment_installments_max  payment_sequential_count  \n",
      "0                       1.0                       3.0  \n",
      "1                       1.0                       1.0  \n",
      "2                       3.0                       1.0  \n",
      "3                       1.0                       1.0  \n",
      "4                       1.0                       1.0  \n",
      "\n",
      "Informações do df_merged (com info de pagamentos agregados):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 33 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      " 14  product_category_name          112650 non-null  object        \n",
      " 15  product_name_lenght            112650 non-null  float64       \n",
      " 16  product_description_lenght     112650 non-null  float64       \n",
      " 17  product_photos_qty             112650 non-null  float64       \n",
      " 18  product_weight_g               112650 non-null  float64       \n",
      " 19  product_length_cm              112650 non-null  float64       \n",
      " 20  product_height_cm              112650 non-null  float64       \n",
      " 21  product_width_cm               112650 non-null  float64       \n",
      " 22  product_category_name_english  112650 non-null  object        \n",
      " 23  customer_unique_id             112650 non-null  object        \n",
      " 24  customer_zip_code_prefix       112650 non-null  int64         \n",
      " 25  customer_city                  112650 non-null  object        \n",
      " 26  customer_state                 112650 non-null  object        \n",
      " 27  seller_zip_code_prefix         112650 non-null  int64         \n",
      " 28  seller_city                    112650 non-null  object        \n",
      " 29  seller_state                   112650 non-null  object        \n",
      " 30  payment_value_total            112647 non-null  float64       \n",
      " 31  payment_installments_max       112647 non-null  float64       \n",
      " 32  payment_sequential_count       112647 non-null  float64       \n",
      "dtypes: datetime64[ns](6), float64(12), int64(3), object(12)\n",
      "memory usage: 28.4+ MB\n",
      "\n",
      "NaNs em 'payment_value_total' após merge: 3\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Relembrando as dimensões\n",
    "print(f\"Dimensões de df_merged (atual): {df_merged.shape}\")\n",
    "\n",
    "# Fazer a junção (merge) com os dados de pagamento agregados\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    payments_summary_df,\n",
    "    on='order_id', # Coluna chave para a junção\n",
    "    how='left'     # Manter todos os itens de pedido, adicionar info de pagamento onde houver\n",
    ")\n",
    "\n",
    "# Verificar as dimensões do DataFrame resultante\n",
    "print(f\"\\nDimensões do df_merged após juntar com payments_summary_df: {df_merged.shape}\")\n",
    "\n",
    "# Exibir as primeiras linhas e informações\n",
    "print(\"\\nPrimeiras linhas do df_merged (com info de pagamentos agregados):\")\n",
    "cols_to_show = ['order_id', 'price', 'payment_value_total', 'payment_installments_max', 'payment_sequential_count']\n",
    "print(df_merged[cols_to_show].head())\n",
    "\n",
    "print(\"\\nInformações do df_merged (com info de pagamentos agregados):\")\n",
    "df_merged.info()\n",
    "\n",
    "# Verificar NaNs nas novas colunas de pagamento\n",
    "print(f\"\\nNaNs em 'payment_value_total' após merge: {df_merged['payment_value_total'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7a65a09-9e16-414a-86d1-1066bc68b719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas (itens de pedido) sem informação de pagamento resumida: 3\n",
      "\n",
      "Detalhes dos itens/pedidos sem informação de pagamento (mostrando colunas relevantes):\n",
      "                               order_id order_status  \\\n",
      "34802  bfbd0f9bdef84302105ad712db648a6c    delivered   \n",
      "34803  bfbd0f9bdef84302105ad712db648a6c    delivered   \n",
      "34804  bfbd0f9bdef84302105ad712db648a6c    delivered   \n",
      "\n",
      "                             product_id  price  payment_value_total  \\\n",
      "34802  5a6b04657a4c5ee34285d1e4619a96b4  44.99                  NaN   \n",
      "34803  5a6b04657a4c5ee34285d1e4619a96b4  44.99                  NaN   \n",
      "34804  5a6b04657a4c5ee34285d1e4619a96b4  44.99                  NaN   \n",
      "\n",
      "       payment_installments_max  payment_sequential_count  \n",
      "34802                       NaN                       NaN  \n",
      "34803                       NaN                       NaN  \n",
      "34804                       NaN                       NaN  \n",
      "\n",
      "Order IDs únicos e seus status para os casos sem informação de pagamento:\n",
      "                               order_id order_status\n",
      "34802  bfbd0f9bdef84302105ad712db648a6c    delivered\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identificar as linhas em df_merged onde as informações de pagamento são NaN\n",
    "linhas_sem_info_pagamento = df_merged[df_merged['payment_value_total'].isnull()]\n",
    "\n",
    "print(f\"Número de linhas (itens de pedido) sem informação de pagamento resumida: {len(linhas_sem_info_pagamento)}\")\n",
    "\n",
    "if len(linhas_sem_info_pagamento) > 0:\n",
    "    print(\"\\nDetalhes dos itens/pedidos sem informação de pagamento (mostrando colunas relevantes):\")\n",
    "    cols_para_investigar = ['order_id', 'order_status', 'product_id', 'price', \n",
    "                            'payment_value_total', 'payment_installments_max', 'payment_sequential_count']\n",
    "    print(linhas_sem_info_pagamento[cols_para_investigar])\n",
    "    \n",
    "    # Ver os order_id únicos e seus status\n",
    "    print(\"\\nOrder IDs únicos e seus status para os casos sem informação de pagamento:\")\n",
    "    print(linhas_sem_info_pagamento[['order_id', 'order_status']].drop_duplicates())\n",
    "else:\n",
    "    print(\"Nenhuma linha encontrada sem informação de pagamento resumida.\")\n",
    "    \n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "560ac121-b18a-443a-ae19-65d145306d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preenchendo NaNs nas colunas de pagamento...\n",
      "NaNs em 'payment_value_total' ANTES: 0\n",
      "NaNs em 'payment_value_total' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'payment_installments_max' ANTES: 0\n",
      "NaNs em 'payment_installments_max' DEPOIS: 0\n",
      "---\n",
      "NaNs em 'payment_sequential_count' ANTES: 0\n",
      "NaNs em 'payment_sequential_count' DEPOIS: 0\n",
      "---\n",
      "\n",
      "Valores ausentes nas colunas de pagamento foram preenchidos.\n",
      "\n",
      "NaNs restantes em 'payment_value_total': 0\n",
      "NaNs restantes em 'payment_installments_max': 0\n",
      "NaNs restantes em 'payment_sequential_count': 0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Verificando os dados de pagamento para o order_id 'bfbd0f9bdef84302105ad712db648a6c':\n",
      "                               order_id order_status  price  \\\n",
      "34802  bfbd0f9bdef84302105ad712db648a6c    delivered  44.99   \n",
      "34803  bfbd0f9bdef84302105ad712db648a6c    delivered  44.99   \n",
      "34804  bfbd0f9bdef84302105ad712db648a6c    delivered  44.99   \n",
      "\n",
      "       payment_value_total  payment_installments_max  payment_sequential_count  \n",
      "34802                  0.0                       0.0                       0.0  \n",
      "34803                  0.0                       0.0                       0.0  \n",
      "34804                  0.0                       0.0                       0.0  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Tipos de dados das colunas de pagamento após preenchimento:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   payment_value_total       112650 non-null  float64\n",
      " 1   payment_installments_max  112650 non-null  float64\n",
      " 2   payment_sequential_count  112650 non-null  float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Os valores que usaremos para preencher os NaNs\n",
    "valores_para_preenchimento = {\n",
    "    'payment_value_total': 0.0,\n",
    "    'payment_installments_max': 0,\n",
    "    'payment_sequential_count': 0\n",
    "}\n",
    "\n",
    "print(\"Preenchendo NaNs nas colunas de pagamento...\")\n",
    "# Preencher os NaNs nas colunas de pagamento especificadas (forma recomendada)\n",
    "for coluna, valor in valores_para_preenchimento.items():\n",
    "    print(f\"NaNs em '{coluna}' ANTES: {df_merged[coluna].isnull().sum()}\")\n",
    "    df_merged[coluna] = df_merged[coluna].fillna(valor) # <-- MUDANÇA AQUI\n",
    "    print(f\"NaNs em '{coluna}' DEPOIS: {df_merged[coluna].isnull().sum()}\")\n",
    "    print(\"---\")\n",
    "\n",
    "\n",
    "print(\"\\nValores ausentes nas colunas de pagamento foram preenchidos.\")\n",
    "\n",
    "# Verificar se os NaNs foram realmente preenchidos (verificação geral)\n",
    "print(f\"\\nNaNs restantes em 'payment_value_total': {df_merged['payment_value_total'].isnull().sum()}\")\n",
    "print(f\"NaNs restantes em 'payment_installments_max': {df_merged['payment_installments_max'].isnull().sum()}\")\n",
    "print(f\"NaNs restantes em 'payment_sequential_count': {df_merged['payment_sequential_count'].isnull().sum()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Vamos conferir os valores para o order_id específico que tinha NaNs\n",
    "order_id_problematico = 'bfbd0f9bdef84302105ad712db648a6c'\n",
    "cols_para_verificar_pagamento = ['order_id', 'order_status', 'price', \n",
    "                                 'payment_value_total', 'payment_installments_max', 'payment_sequential_count']\n",
    "print(f\"Verificando os dados de pagamento para o order_id '{order_id_problematico}':\")\n",
    "print(df_merged[df_merged['order_id'] == order_id_problematico][cols_para_verificar_pagamento])\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Re-verificar os tipos de dados das colunas de pagamento após o preenchimento\n",
    "print(\"Tipos de dados das colunas de pagamento após preenchimento:\")\n",
    "print(df_merged[['payment_value_total', 'payment_installments_max', 'payment_sequential_count']].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "145dcd65-b086-4896-b2b1-a9286af0615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pedidos com mais de uma avaliação: 547\n",
      "\n",
      "Exemplos de pedidos com múltiplas avaliações e suas contagens:\n",
      "order_id\n",
      "03c939fd7fd3b38f8485a0f95798f1f6    3\n",
      "8e17072ec97ce29f0e1f111e598b0c85    3\n",
      "c88b1d1b157a9999ce368f218a407141    3\n",
      "df56136b8031ecd28e200bb18e6ddb2e    3\n",
      "02355020fd0a40a0d56df9f6ff060413    2\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que order_reviews_df está carregado e com as datas convertidas\n",
    "# (já fizemos isso anteriormente no notebook 02_limpeza_dados.ipynb).\n",
    "\n",
    "# Contar quantas avaliações cada order_id possui\n",
    "contagem_avaliacoes_por_pedido = order_reviews_df.groupby('order_id').size()\n",
    "\n",
    "# Verificar quantos pedidos têm mais de uma avaliação\n",
    "pedidos_com_multiplas_avaliacoes = contagem_avaliacoes_por_pedido[contagem_avaliacoes_por_pedido > 1]\n",
    "num_pedidos_multiplas_avaliacoes = len(pedidos_com_multiplas_avaliacoes)\n",
    "\n",
    "print(f\"Número de pedidos com mais de uma avaliação: {num_pedidos_multiplas_avaliacoes}\")\n",
    "\n",
    "if num_pedidos_multiplas_avaliacoes > 0:\n",
    "    print(\"\\nExemplos de pedidos com múltiplas avaliações e suas contagens:\")\n",
    "    print(pedidos_com_multiplas_avaliacoes.sort_values(ascending=False).head())\n",
    "else:\n",
    "    print(\"Nenhum pedido tem mais de uma avaliação. Cada pedido tem no máximo uma avaliação.\")\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "828380fe-3bab-4d0f-9451-1c9d1070eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões originais de order_reviews_df: (99224, 7)\n",
      "\n",
      "Número de pedidos com mais de uma avaliação APÓS deduplicação: 0\n",
      "Dimensões de order_reviews_df_deduplicated: (98673, 7)\n",
      "Este número de linhas deve ser igual ao número de order_id únicos no order_reviews_df original.\n",
      "Número de order_id únicos no order_reviews_df original: 98673\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Dimensões de df_merged (atual): (112650, 33)\n",
      "\n",
      "Dimensões do df_merged após juntar com order_reviews_df_deduplicated: (112650, 39)\n",
      "\n",
      "Informações do df_merged final:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 39 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       112650 non-null  object        \n",
      " 1   customer_id                    112650 non-null  object        \n",
      " 2   order_status                   112650 non-null  object        \n",
      " 3   order_purchase_timestamp       112650 non-null  datetime64[ns]\n",
      " 4   order_approved_at              112635 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   111456 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  110196 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  112650 non-null  datetime64[ns]\n",
      " 8   order_item_id                  112650 non-null  int64         \n",
      " 9   product_id                     112650 non-null  object        \n",
      " 10  seller_id                      112650 non-null  object        \n",
      " 11  shipping_limit_date            112650 non-null  datetime64[ns]\n",
      " 12  price                          112650 non-null  float64       \n",
      " 13  freight_value                  112650 non-null  float64       \n",
      " 14  product_category_name          112650 non-null  object        \n",
      " 15  product_name_lenght            112650 non-null  float64       \n",
      " 16  product_description_lenght     112650 non-null  float64       \n",
      " 17  product_photos_qty             112650 non-null  float64       \n",
      " 18  product_weight_g               112650 non-null  float64       \n",
      " 19  product_length_cm              112650 non-null  float64       \n",
      " 20  product_height_cm              112650 non-null  float64       \n",
      " 21  product_width_cm               112650 non-null  float64       \n",
      " 22  product_category_name_english  112650 non-null  object        \n",
      " 23  customer_unique_id             112650 non-null  object        \n",
      " 24  customer_zip_code_prefix       112650 non-null  int64         \n",
      " 25  customer_city                  112650 non-null  object        \n",
      " 26  customer_state                 112650 non-null  object        \n",
      " 27  seller_zip_code_prefix         112650 non-null  int64         \n",
      " 28  seller_city                    112650 non-null  object        \n",
      " 29  seller_state                   112650 non-null  object        \n",
      " 30  payment_value_total            112650 non-null  float64       \n",
      " 31  payment_installments_max       112650 non-null  float64       \n",
      " 32  payment_sequential_count       112650 non-null  float64       \n",
      " 33  review_id                      111708 non-null  object        \n",
      " 34  review_score                   111708 non-null  float64       \n",
      " 35  review_comment_title           13415 non-null   object        \n",
      " 36  review_comment_message         47398 non-null   object        \n",
      " 37  review_creation_date           111708 non-null  datetime64[ns]\n",
      " 38  review_answer_timestamp        111708 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](8), float64(13), int64(3), object(15)\n",
      "memory usage: 33.5+ MB\n",
      "\n",
      "Número de NaNs em 'review_score' no df_merged final: 942\n",
      "Isso significa que 111708 itens de pedido têm uma avaliação associada.\n",
      "\n",
      "Nomes das colunas finais no df_merged:\n",
      "['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm', 'product_category_name_english', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state', 'seller_zip_code_prefix', 'seller_city', 'seller_state', 'payment_value_total', 'payment_installments_max', 'payment_sequential_count', 'review_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Certifique-se de que order_reviews_df está carregado e com as datas convertidas.\n",
    "\n",
    "print(\"Dimensões originais de order_reviews_df:\", order_reviews_df.shape)\n",
    "\n",
    "# 1. Ordenar as avaliações:\n",
    "#   - Por order_id (para agrupar)\n",
    "#   - Depois por review_answer_timestamp DESCENDENTE (a mais recente primeiro)\n",
    "#   - Depois por review_score DESCENDENTE (o maior score primeiro, como critério de desempate)\n",
    "order_reviews_df_sorted = order_reviews_df.sort_values(\n",
    "    by=['order_id', 'review_answer_timestamp', 'review_score'],\n",
    "    ascending=[True, False, False]  # True para order_id, False para os outros dois\n",
    ")\n",
    "\n",
    "# 2. Remover duplicatas de 'order_id', mantendo a PRIMEIRA ocorrência.\n",
    "#    Como ordenamos, a primeira será a mais recente / com maior score.\n",
    "order_reviews_df_deduplicated = order_reviews_df_sorted.drop_duplicates(\n",
    "    subset=['order_id'],  # Considerar duplicatas com base apenas em order_id\n",
    "    keep='first'          # Manter a primeira linha após a ordenação\n",
    ")\n",
    "\n",
    "# 3. Verificar se a deduplicação funcionou\n",
    "contagem_avaliacoes_dedup = order_reviews_df_deduplicated.groupby('order_id').size()\n",
    "num_pedidos_multiplas_avaliacoes_depois = sum(contagem_avaliacoes_dedup > 1)\n",
    "print(f\"\\nNúmero de pedidos com mais de uma avaliação APÓS deduplicação: {num_pedidos_multiplas_avaliacoes_depois}\")\n",
    "print(f\"Dimensões de order_reviews_df_deduplicated: {order_reviews_df_deduplicated.shape}\")\n",
    "print(\"Este número de linhas deve ser igual ao número de order_id únicos no order_reviews_df original.\")\n",
    "print(f\"Número de order_id únicos no order_reviews_df original: {order_reviews_df['order_id'].nunique()}\")\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "# 6.2. Juntando df_merged com order_reviews_df_deduplicated\n",
    "\n",
    "print(f\"Dimensões de df_merged (atual): {df_merged.shape}\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_merged,\n",
    "    order_reviews_df_deduplicated, # Usamos o DataFrame deduzido\n",
    "    on='order_id',\n",
    "    how='left'  # Manter todos os itens de pedido; adicionar info de avaliação se existir\n",
    ")\n",
    "\n",
    "# Verificar as dimensões e informações finais\n",
    "print(f\"\\nDimensões do df_merged após juntar com order_reviews_df_deduplicated: {df_merged.shape}\")\n",
    "print(\"\\nInformações do df_merged final:\")\n",
    "df_merged.info()\n",
    "\n",
    "# Verificar quantos NaNs temos em 'review_score'.\n",
    "# É esperado ter NaNs aqui, pois nem todo pedido tem uma avaliação.\n",
    "num_nans_review_score = df_merged['review_score'].isnull().sum()\n",
    "print(f\"\\nNúmero de NaNs em 'review_score' no df_merged final: {num_nans_review_score}\")\n",
    "print(f\"Isso significa que {len(df_merged) - num_nans_review_score} itens de pedido têm uma avaliação associada.\")\n",
    "\n",
    "print(\"\\nNomes das colunas finais no df_merged:\")\n",
    "print(list(df_merged.columns))\n",
    "print(\"\\n--------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c23504a-da53-4bc1-81ba-3377849d777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame df_merged salvo com sucesso em: dados/olist_df_merged_para_analise.csv\n",
      "Dimensões do df_merged salvo: (112650, 39)\n",
      "Verifique as primeiras linhas do df_merged antes de salvar para referência:\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp   order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33 2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37 2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49 2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06 2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39 2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  order_item_id  \\\n",
      "0                    2017-10-18              1   \n",
      "1                    2018-08-13              1   \n",
      "2                    2018-09-04              1   \n",
      "3                    2017-12-15              1   \n",
      "4                    2018-02-26              1   \n",
      "\n",
      "                         product_id  ... seller_state payment_value_total  \\\n",
      "0  87285b34884572647811a353c7ac498a  ...           SP               38.71   \n",
      "1  595fac2a385ac33a80bd5114aec74eb8  ...           SP              141.46   \n",
      "2  aa4383b373c6aca5d8797843e5594415  ...           SP              179.12   \n",
      "3  d0b61bfb1de832b15ba9d266ca96e5b0  ...           MG               72.20   \n",
      "4  65266b2da20d04dbe00c5c2d3bb7859e  ...           SP               28.62   \n",
      "\n",
      "   payment_installments_max  payment_sequential_count  \\\n",
      "0                       1.0                       3.0   \n",
      "1                       1.0                       1.0   \n",
      "2                       3.0                       1.0   \n",
      "3                       1.0                       1.0   \n",
      "4                       1.0                       1.0   \n",
      "\n",
      "                          review_id  review_score  review_comment_title  \\\n",
      "0  a54f0611adc9ed256b57ede6b6eb5114           4.0                   NaN   \n",
      "1  8d5266042046a06655c8db133d120ba5           4.0      Muito boa a loja   \n",
      "2  e73b67b67587f7644d5bd1a52deb1b01           5.0                   NaN   \n",
      "3  359d03e676b3c069f62cadba8dd3f6e8           5.0                   NaN   \n",
      "4  e50934924e227544ba8246aeb3770dd4           5.0                   NaN   \n",
      "\n",
      "                              review_comment_message  review_creation_date  \\\n",
      "0  Não testei o produto ainda, mas ele veio corre...            2017-10-11   \n",
      "1                               Muito bom o produto.            2018-08-08   \n",
      "2                                                NaN            2018-08-18   \n",
      "3  O produto foi exatamente o que eu esperava e e...            2017-12-03   \n",
      "4                                                NaN            2018-02-17   \n",
      "\n",
      "   review_answer_timestamp  \n",
      "0      2017-10-12 03:43:48  \n",
      "1      2018-08-08 18:37:50  \n",
      "2      2018-08-22 19:07:58  \n",
      "3      2017-12-05 19:21:58  \n",
      "4      2018-02-18 13:02:51  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# No final do notebook 02_limpeza_dados.ipynb\n",
    "\n",
    "# Certifique-se de que 'df_merged' é o seu DataFrame final e completo\n",
    "# Salvar o DataFrame em um arquivo CSV\n",
    "caminho_arquivo_salvo = os.path.join(data_path, 'olist_df_merged_विश्लेषणाकरिता.csv') # 'विश्लेषणाकरिता' significa 'para análise' em Marati, mas podemos usar um nome mais simples se preferir, como 'olist_df_merged_para_analise.csv'\n",
    "# Vamos usar um nome mais simples para evitar problemas com caracteres especiais no nome do arquivo em alguns sistemas:\n",
    "caminho_arquivo_salvo = os.path.join(data_path, 'olist_df_merged_para_analise.csv')\n",
    "\n",
    "df_merged.to_csv(caminho_arquivo_salvo, index=False) # index=False para não salvar o índice do DataFrame como uma coluna no CSV\n",
    "\n",
    "print(f\"DataFrame df_merged salvo com sucesso em: {caminho_arquivo_salvo}\")\n",
    "print(f\"Dimensões do df_merged salvo: {df_merged.shape}\")\n",
    "print(\"Verifique as primeiras linhas do df_merged antes de salvar para referência:\")\n",
    "print(df_merged.head()) # Apenas para você ter uma última olhada antes de mudar de notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a51c54-059b-4bce-9dc3-21a4474a52b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
